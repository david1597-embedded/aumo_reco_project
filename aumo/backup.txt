# class ModelLoader:
#     def __init__(self, model_name: str, imgsz: int = DEFAULT_IMGSZ):
#         self.model_name = model_name
#         self.imgsz = imgsz
#         ensure_dirs(MODEL_PATH, ONNX_PATH, XML_PATH)
#         self.model = None

#     def load(self):
#         model_path = os.path.join(MODEL_PATH, f"{self.model_name}.pt")
#         if not os.path.exists(model_path):
#             # í˜„ì¬ ì‘ì—… ë””ë ‰í„°ë¦¬ì— .ptê°€ ìˆìœ¼ë©´ MODEL_PATHë¡œ ì´ë™
#             if os.path.exists(f"{self.model_name}.pt"):
#                 os.rename(f"{self.model_name}.pt", model_path)
#             else:
#                 raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ {self.model_name}.ptë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

#         self.model = YOLO(model_path)

#         print(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {self.model.model_name}")
#         return self.model

#     def export(self):
#         if self.model is None:
#             raise RuntimeError("ëª¨ë¸ì„ ë¨¼ì € load() í•´ì•¼ í•©ë‹ˆë‹¤.")
#         onnx_file = os.path.join(ONNX_PATH, f"{self.model_name}.onnx")
#         if not os.path.exists(onnx_file):
#             print(f"ONNXë¡œ export ì¤‘...: {onnx_file}")
#             export_onnx(self.model, output=onnx_file)
#         else:
#             print(f"ONNX íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {onnx_file}")
#         return onnx_file

#     def convert(self):
#         xml_file = os.path.join(XML_PATH, f"{self.model_name}.xml")
#         onnx_file = os.path.join(ONNX_PATH, f"{self.model_name}.onnx")
#         if not os.path.exists(xml_file):
#             print(f"OpenVINOë¡œ ë³€í™˜ ì¤‘...: {xml_file}")
#             convert_openvino(onnx_file, output=xml_file)
#         else:
#             print(f"OpenVINO íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {xml_file}")
#         return xml_file


from ultralytics import YOLO
import openvino as ov
import os
from typing import Tuple
from .utils import path_and_name
from .config import MODEL_PATH

def export_onnx(model: YOLO, imgsz: int =640, output: str = None) -> bool:
    try:
        model.export(format='onnx', imgsz=imgsz)
        default_onnx = f"{os.path.splitext(model.model_name)[0]}.onnx"

        if output is None:output = default_onnx
        else : os.rename(default_onnx, output)
        print(f"[OK] ONNX export complete: {output}")
        
        return True
    
    except Exception as e:
        print(f"[Error] ONNX export failed: {e}")
        
        return False

def convert_openvino(onnx_path: str, output: str = None) -> bool:
    if output is None:
        dir_path, name = path_and_name(onnx_path)
        output = os.path.join(dir_path, f"{name}.xml")
    try:
        ov_model = ov.convert_model(onnx_path)
        ov.save_model(ov_model, output)
        print(f"[OK] OpenVINO conversion complete: {output}")
        return True
    except Exception as e:
        print(f"[Error] OpenVINO conversion failed: {e}")
        return False



import os

def ensure_dirs(*dirs):
    for d in dirs:
        os.makedirs(d, exist_ok=True)

def path_and_name(path: str):
    dir_path = os.path.dirname(path)
    name, _ = os.path.splitext(os.path.basename(path))
    return dir_path, name


import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models, transforms, datasets
from torch.utils.data import DataLoader
import os

def train_resnet50(class_dict, size=(512, 512), batch_size=64, epochs=10):
    # print(class_dict)
    print(size, epochs)
    os.makedirs('models', exist_ok=True)
    
    class_to_idx = {v: k for k, v in class_dict.items()}
    # print(class_to_idx)

    # class_order = ["no_gesture", "fist", "one", "peace", "peace_inverted",
    #     "two_up", "two_up_inverted", "three", "three2", "four",
    #     "stop", "stop_inverted", "rock"]

    # ğŸ”· 1. ë°ì´í„°ì…‹ & ì „ì²˜ë¦¬
    transform = transforms.Compose([
        transforms.Resize(size),      # ResNet ì…ë ¥ í¬ê¸°
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                            std=[0.229, 0.224, 0.225])
    ])

    train_dataset = datasets.ImageFolder(root='datasets/train', transform=transform)
    train_dataset.class_to_idx = class_to_idx
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)

    # val_dataset = datasets.ImageFolder(root='your_val_dir', transform=transform)
    # val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)

    num_classes = len(train_dataset.classes)  # í´ë˜ìŠ¤ ìˆ˜ ìë™ ê³„ì‚°

    # ğŸ”· 2. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    model = models.resnet50(pretrained=True)

    # ğŸ”· 3. ë§ˆì§€ë§‰ layer êµì²´
    model.fc = nn.Linear(model.fc.in_features, num_classes)

    # GPUë¡œ
    device = torch.device("cuda:1" if torch.cuda.is_available() else "cpu")
    print(device)
    model = model.to(device)

    # ğŸ”· 4. í•™ìŠµ ì„¤ì •
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=1e-4)

    # ğŸ”· (ì„ íƒ) Feature Extractorë¡œë§Œ ì‚¬ìš©í•˜ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ì²˜ëŸ¼ ë™ê²°
    # for param in model.parameters():
    #     param.requires_grad = False
    # model.fc.weight.requires_grad = True
    # model.fc.bias.requires_grad = True
    # optimizer = optim.Adam(model.fc.parameters(), lr=1e-3)

    # ğŸ”· 5. í•™ìŠµ ë£¨í”„
    for epoch in range(epochs):
        model.train()
        running_loss = 0.0
        for imgs, labels in train_loader:
            imgs, labels = imgs.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(imgs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

        print(f"[Epoch {epoch+1}/{epochs}] Loss: {running_loss/len(train_loader):.4f}")

        # ğŸ”· (ì„ íƒ) validation
        # model.eval()
        # correct, total = 0, 0
        # with torch.no_grad():
        #     for imgs, labels in val_loader:
        #         imgs, labels = imgs.to(device), labels.to(device)
        #         outputs = model(imgs)
        #         _, preds = torch.max(outputs, 1)
        #         correct += (preds == labels).sum().item()
        #         total += labels.size(0)

        # val_acc = correct / total
        # print(f"Validation Accuracy: {val_acc:.4f}")

    print("âœ… í•™ìŠµ ì™„ë£Œ!")

    torch.save(model.state_dict(), f'models/resnet50_{size[0]}_{epochs}.pth')
    print("âœ… ì €ì¥ ì™„ë£Œ!")